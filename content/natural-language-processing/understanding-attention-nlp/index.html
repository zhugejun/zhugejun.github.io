<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.276">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-03-10">

<title>Understanding Transformer Architecture by Building GPT</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  </head><body>true





<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.md"><i class="bi bi-file"></i>CommonMark (hugo)</a></li></ul></div></div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Understanding Transformer Architecture by Building GPT</h1>
  <div class="quarto-categories">
    <div class="quarto-category">NLP</div>
    <div class="quarto-category">Python</div>
    <div class="quarto-category">Transformer</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 10, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>{{&lt; youtube kCc8FmEb1nY &gt;}}</p>
<p>In [Part2], we built a simple MLP model to generate characters based on 32k popular names. In this lecture, Andrej shows us how to understand and add transformer architecture gradually to improve our bigram model performance. In other words, we started from refactoring our previous bigram model, then add piece by piece of code from transformer architecture and see how it improves our model.</p>
<p><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need</a></p>
<section id="data-preparation" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation">Data Preparation</h2>
<p>Let’s first import the necessary libraries and get the data ready. This time we are using the tiny shakespeare dataset.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>data_url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>data_url <span class="op">=</span> <span class="st">"https://t.ly/u1Ax"</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> requests.get(data_url).text</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># building vocabulary</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(text)))</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>vocab_size <span class="op">=</span> <span class="bu">len</span>(chars)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">""</span>.join(chars))</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Vocabulary size: </span><span class="sc">{</span>vocab_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># mappings</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>stoi <span class="op">=</span> {c: i <span class="cf">for</span> i, c <span class="kw">in</span> <span class="bu">enumerate</span>(chars)}</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>itos <span class="op">=</span> {v: k <span class="cf">for</span> k, v <span class="kw">in</span> stoi.items()}</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> encode(s): <span class="cf">return</span> [stoi[c] <span class="cf">for</span> c <span class="kw">in</span> s]</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> decode(l): <span class="cf">return</span> <span class="st">''</span>.join([itos[i] <span class="cf">for</span> i <span class="kw">in</span> l])</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># create tensor</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> torch.tensor(encode(text), dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.9</span><span class="op">*</span><span class="bu">len</span>(data))</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> data[:n]</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>val_data <span class="op">=</span> data[n:]</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_data.shape)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(val_data.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
 !$&amp;',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
Vocabulary size: 65
torch.Size([1003854])
torch.Size([111540])</code></pre>
</div>
</div>
<section id="vocabulary" class="level3">
<h3 class="anchored" data-anchor-id="vocabulary">Vocabulary</h3>
<p>We have 65 characters, including all lower- and upper-case leters and a few spcecial characters <code>\n !$&amp;',-.3:;?</code>.</p>
</section>
<section id="training-data" class="level3">
<h3 class="anchored" data-anchor-id="training-data">Training Data</h3>
<p>There is no attention in the model yet. Got to rewrite this.</p>
<p>The transformer can only see the characters up to the <code>block_size</code>, which can be considered as a time dimension. In other words, our context for each block is all characters before time <code>t</code> inside the block, and the target is the character at time <code>t</code>. Is this a <span class="math inline">\(n\)</span>-gram model? No, because there is no fixed <span class="math inline">\(n\)</span> in the model. The model generate one character at a time. Once it genrates multiple characters, it can look back and pays attention to what it has generated and generate another character based on previous characters up to the <code>block_size</code>. To generate characters, the model starts sampling from our vocabulary and generates the first character. Based on the character generated, the model generates another character, and then generates the next character based on the previous two characters, etc. The model stops generating until it reaches the limit of the sequence.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>block_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> train_data[:block_size]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> train_data[<span class="dv">1</span>:block_size<span class="op">+</span><span class="dv">1</span>]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(block_size):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    context <span class="op">=</span> x[:t<span class="op">+</span><span class="dv">1</span>]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    target <span class="op">=</span> y[t]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Time: </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">, input: </span><span class="sc">{</span>context<span class="sc">}</span><span class="ss">, target: </span><span class="sc">{</span>target<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Time: 0, input: tensor([18]), target: 47
Time: 1, input: tensor([18, 47]), target: 56
Time: 2, input: tensor([18, 47, 56]), target: 57
Time: 3, input: tensor([18, 47, 56, 57]), target: 58
Time: 4, input: tensor([18, 47, 56, 57, 58]), target: 1
Time: 5, input: tensor([18, 47, 56, 57, 58,  1]), target: 15
Time: 6, input: tensor([18, 47, 56, 57, 58,  1, 15]), target: 47
Time: 7, input: tensor([18, 47, 56, 57, 58,  1, 15, 47]), target: 58</code></pre>
</div>
</div>
</section>
<section id="batch-processing" class="level3">
<h3 class="anchored" data-anchor-id="batch-processing">Batch Processing</h3>
<p>Each time, the model randomly samples <code>batch_size</code> blocks to create <code>batch_size</code> times <code>block_size</code> training observations to calculate its loss and update weights accordingly.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>block_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_batch(split):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> train_data <span class="cf">if</span> split <span class="op">==</span> <span class="st">"train"</span> <span class="cf">else</span> val_data</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> torch.randint(<span class="bu">len</span>(data) <span class="op">-</span> block_size, (batch_size,))</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.stack([data[i:i<span class="op">+</span>block_size] <span class="cf">for</span> i <span class="kw">in</span> idx])</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> torch.stack([data[i<span class="op">+</span><span class="dv">1</span>:i<span class="op">+</span>block_size<span class="op">+</span><span class="dv">1</span>] <span class="cf">for</span> i <span class="kw">in</span> idx])</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> x.to(device), y.to(device)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x, y</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>x_batch, y_batch <span class="op">=</span> get_batch(<span class="st">"train"</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_batch.shape, y_batch.shape)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"---------- Batch </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss"> ----------"</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(block_size):</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        context <span class="op">=</span> x_batch[b, :t<span class="op">+</span><span class="dv">1</span>] </span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        target <span class="op">=</span> y_batch[b, t]</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Time: </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">, input: </span><span class="sc">{</span>context<span class="sc">}</span><span class="ss">, target: </span><span class="sc">{</span>target<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([4, 8]) torch.Size([4, 8])
---------- Batch 0 ----------
Time: 0, input: tensor([58], device='cuda:0'), target: 39
Time: 1, input: tensor([58, 39], device='cuda:0'), target: 49
Time: 2, input: tensor([58, 39, 49], device='cuda:0'), target: 43
Time: 3, input: tensor([58, 39, 49, 43], device='cuda:0'), target: 1
Time: 4, input: tensor([58, 39, 49, 43,  1], device='cuda:0'), target: 51
Time: 5, input: tensor([58, 39, 49, 43,  1, 51], device='cuda:0'), target: 63
Time: 6, input: tensor([58, 39, 49, 43,  1, 51, 63], device='cuda:0'), target: 1
Time: 7, input: tensor([58, 39, 49, 43,  1, 51, 63,  1], device='cuda:0'), target: 56
---------- Batch 1 ----------
Time: 0, input: tensor([54], device='cuda:0'), target: 58
Time: 1, input: tensor([54, 58], device='cuda:0'), target: 0
Time: 2, input: tensor([54, 58,  0], device='cuda:0'), target: 32
Time: 3, input: tensor([54, 58,  0, 32], device='cuda:0'), target: 46
Time: 4, input: tensor([54, 58,  0, 32, 46], device='cuda:0'), target: 43
Time: 5, input: tensor([54, 58,  0, 32, 46, 43], device='cuda:0'), target: 1
Time: 6, input: tensor([54, 58,  0, 32, 46, 43,  1], device='cuda:0'), target: 50
Time: 7, input: tensor([54, 58,  0, 32, 46, 43,  1, 50], device='cuda:0'), target: 43
---------- Batch 2 ----------
Time: 0, input: tensor([44], device='cuda:0'), target: 59
Time: 1, input: tensor([44, 59], device='cuda:0'), target: 50
Time: 2, input: tensor([44, 59, 50], device='cuda:0'), target: 1
Time: 3, input: tensor([44, 59, 50,  1], device='cuda:0'), target: 58
Time: 4, input: tensor([44, 59, 50,  1, 58], device='cuda:0'), target: 53
Time: 5, input: tensor([44, 59, 50,  1, 58, 53], device='cuda:0'), target: 1
Time: 6, input: tensor([44, 59, 50,  1, 58, 53,  1], device='cuda:0'), target: 58
Time: 7, input: tensor([44, 59, 50,  1, 58, 53,  1, 58], device='cuda:0'), target: 46
---------- Batch 3 ----------
Time: 0, input: tensor([52], device='cuda:0'), target: 44
Time: 1, input: tensor([52, 44], device='cuda:0'), target: 59
Time: 2, input: tensor([52, 44, 59], device='cuda:0'), target: 50
Time: 3, input: tensor([52, 44, 59, 50], device='cuda:0'), target: 50
Time: 4, input: tensor([52, 44, 59, 50, 50], device='cuda:0'), target: 63
Time: 5, input: tensor([52, 44, 59, 50, 50, 63], device='cuda:0'), target: 10
Time: 6, input: tensor([52, 44, 59, 50, 50, 63, 10], device='cuda:0'), target: 1
Time: 7, input: tensor([52, 44, 59, 50, 50, 63, 10,  1], device='cuda:0'), target: 46</code></pre>
</div>
</div>
</section>
</section>
<section id="bigramlanguagemodel" class="level2">
<h2 class="anchored" data-anchor-id="bigramlanguagemodel">BigramLanguageModel</h2>
<p>Let’s rewrite our previous bigram model. Here is the main part of the model we build in [Part 1].</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> torch.randn((<span class="dv">27</span>, <span class="dv">27</span>), requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> xenc <span class="op">@</span> W </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> logits.exp()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> counts <span class="op">/</span> counts.<span class="bu">sum</span>(<span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="base-model" class="level3">
<h3 class="anchored" data-anchor-id="base-model">Base model</h3>
<p>From [Part 2], we learned about how to use embedding, a real-value vector of fixed size, to represent a character. We can use PyTorch built-in <a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"><code>nn.Embedding</code></a> to initialize the embedding matrix for our model. The size of each embedding we are using this time is 64 instead of the size of our vocabulary. Because of this, we have to create another linear layer to make sure the size of the output equals the size of our vocabulary.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>n_embed <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BigramLanguageModel(nn.Module):</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size):</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.token_embedding_table <span class="op">=</span> nn.Embedding(vocab_size, n_embed) <span class="co"># 65, C</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(n_embed, vocab_size) <span class="co"># C, 65</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, idx, targets<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        embedded <span class="op">=</span> <span class="va">self</span>.token_embedding_table(idx) <span class="co"># B, T, C</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.linear(embedded) <span class="co"># B, T, 65</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># there is no target when predicting</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> targets <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="va">None</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>            B, T, C <span class="op">=</span> logits.shape</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> logits.view(B<span class="op">*</span>T, C) <span class="co"># (N, C)</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> targets.view(B<span class="op">*</span>T)  <span class="co"># (N)</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> F.cross_entropy(logits, targets)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits, loss</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate(<span class="va">self</span>, idx, max_length):</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(max_length):</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(idx)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>            logits, _ <span class="op">=</span> <span class="va">self</span>(idx)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>            <span class="co"># focus on the char on last time stamp because it's a bigram model</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> logits[:, <span class="op">-</span><span class="dv">1</span>, :] <span class="co"># B, C</span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>            idx_next <span class="op">=</span> torch.multinomial(probs, num_samples<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>            <span class="co"># concatenate the new generated to the old ones</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> torch.cat((idx, idx_next), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> idx</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BigramLanguageModel(vocab_size).to(device)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> torch.zeros((<span class="dv">1</span>, <span class="dv">1</span>), dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>device)</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(decode(model.generate(idx, max_length<span class="op">=</span><span class="dv">10</span>).squeeze().tolist()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0]], device='cuda:0')</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0, 42]], device='cuda:0')
tensor([[ 0, 42, 18]], device='cuda:0')
tensor([[ 0, 42, 18,  9]], device='cuda:0')
tensor([[ 0, 42, 18,  9, 59]], device='cuda:0')
tensor([[ 0, 42, 18,  9, 59, 52]], device='cuda:0')
tensor([[ 0, 42, 18,  9, 59, 52, 18]], device='cuda:0')
tensor([[ 0, 42, 18,  9, 59, 52, 18, 15]], device='cuda:0')
tensor([[ 0, 42, 18,  9, 59, 52, 18, 15, 11]], device='cuda:0')
tensor([[ 0, 42, 18,  9, 59, 52, 18, 15, 11, 30]], device='cuda:0')

dF3unFC;Rn</code></pre>
</div>
</div>
<p>Of course, the generated 100 characters don’t make any sense because we haven’t trained our model yet.</p>
</section>
<section id="training" class="level3">
<h3 class="anchored" data-anchor-id="training">Training</h3>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># training</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">20000</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    x_batch, y_batch <span class="op">=</span> get_batch(<span class="st">"train"</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    logits, loss <span class="op">=</span> model(x_batch, y_batch)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">1000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0: 4.440201282501221</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1000: 2.5844924449920654</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 2000: 2.469000816345215</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 3000: 2.473245859146118</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 4000: 2.4555399417877197</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 5000: 2.5115771293640137</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 6000: 2.3323276042938232</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 7000: 2.331480026245117</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 8000: 2.436919927597046</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 9000: 2.473867893218994</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 10000: 2.4798736572265625</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 11000: 2.4582247734069824</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 12000: 2.5296058654785156</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 13000: 2.372481346130371</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 14000: 2.4686214923858643</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 15000: 2.4755468368530273</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 16000: 2.437105894088745</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 17000: 2.4874863624572754</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 18000: 2.550337553024292</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 19000: 2.354231119155884</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 2.4072229862213135</code></pre>
</div>
</div>
</section>
<section id="word-generation" class="level3">
<h3 class="anchored" data-anchor-id="word-generation">Word Generation</h3>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># generating</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> torch.zeros((<span class="dv">1</span>, <span class="dv">1</span>), dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>device)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(decode(model.generate(idx, max_length<span class="op">=</span><span class="dv">100</span>).squeeze().tolist()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0]], device='cuda:0')
tensor([[ 0, 13]], device='cuda:0')
tensor([[ 0, 13, 57]], device='cuda:0')
tensor([[ 0, 13, 57,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58]],
       device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6,  1, 53]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6,  1, 53,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6,  1, 53,  1, 63]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6,  1, 53,  1, 63,  1]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6,  1, 53,  1, 63,  1, 47]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6,  1, 53,  1, 63,  1, 47, 52]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6,  1, 53,  1, 63,  1, 47, 52, 42]], device='cuda:0')
tensor([[ 0, 13, 57,  1, 58, 47, 57, 58,  1, 58, 43,  1, 53, 58, 46, 59, 56,  1,
         51, 53, 42,  1, 58, 46, 39, 52, 42,  1, 46, 43,  6,  1, 54, 56, 43, 41,
         49, 52,  6,  0, 27, 24, 21, 21,  1, 44,  1, 44,  1, 53,  7,  7, 61, 47,
         58, 46, 43, 50, 39, 54, 47, 52, 47, 57, 43, 56, 57,  1, 61, 43,  1, 40,
         59, 56, 53, 56, 43, 39, 52,  6,  0, 32, 13, 33, 15, 50, 59, 54, 56, 58,
          6,  1, 53,  1, 63,  1, 47, 52, 42, 43]], device='cuda:0')

As tist te othur mod thand he, preckn,
OLII f f o--withelapinisers we burorean,
TAUCluprt, o y inde </code></pre>
</div>
</div>
<p>Let’s see how we can incorporate the transformer, specifically the decoder part, into our model to improve its performance. As we can see that our bigram model only looks at the last generated character. How can we accumulate all the information from the previous generated characters so that we can improve our model performance? One way is to use a bag-of-words model which extracts freatures from previous generated characters.</p>
</section>
</section>
<section id="encoder-decoder-architecture" class="level2">
<h2 class="anchored" data-anchor-id="encoder-decoder-architecture">Encoder-Decoder architecture</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="transformer-architecture.jpg" class="quarto-discovered-preview-image img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">encoder-decoder-architecture</figcaption><p></p>
</figure>
</div>
<p>The left side of the architecture is an encoder which encodes the information from the input sequence into a numerical representation.</p>
<blockquote class="blockquote">
<p>The encoder maps an input sequence of symbol representations <span class="math inline">\((x_1, ..., x_n)\)</span> to a sequence of continuous representations <span class="math inline">\(z=(z_1, ..., z_n)\)</span>. It converts an input sequence of tokens into a sequence of embedding vectors which is often called hidden state. The encoder is composed of a stack of encoder layers, which are used to update the input embeddings to produce representations taht encode some contexual information in the sequence.</p>
</blockquote>
<p>The right side of the architecture is a decoder. The state generated from the encoder is then passed to the decoder and generate the output sequence.</p>
<p>A decoder uses encoder’s hidden state to iteratively generate an output sequence of tokens, one at a time. The docoder is also composed of a stack of decoder layers.</p>
<p>The encoder’s output is fed to each decoder layer, and the decoder then generates a prediction for the most probable next token in the sequence. The output of this step is then fed back into the decoder to generate the next token, and so on until a special end-of-sequence token is reached. The input words are fed sequentially through the encoder and the output words are generated one at a time.</p>
<section id="encoder-only" class="level3">
<h3 class="anchored" data-anchor-id="encoder-only">Encoder-only</h3>
<p>BERT stands for Bidirectional Encoder Representations from Transformers. A representation computed from BERT depends on both on the left and the right contexts. This is often called bidirectional attention. These models are suitable for text classification and named entity recoginition.</p>
</section>
<section id="decoder-only" class="level3">
<h3 class="anchored" data-anchor-id="decoder-only">Decoder-only</h3>
<p>GPT, which stands for Generative Pretrained Transformer. The representation computed for a given token in this architecture depends only on the left context. This is often called autoregressive attention. What is auto-regressive? Consume the previously generated symbols as additional input when generating the next.</p>
</section>
<section id="encoder-decoder" class="level3">
<h3 class="anchored" data-anchor-id="encoder-decoder">Encoder-Decoder</h3>
<p>This architecture is used for modeling complex mappings from one sequence to another, such as machine translation.</p>
<p>Since we are going to build a character-based GPT, our model architecture becomes the following.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="GPT.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">gpt-architecture</figcaption><p></p>
</figure>
</div>
<p>Let’s build the model from bottom to top.</p>
</section>
</section>
<section id="positional-embedding" class="level2">
<h2 class="anchored" data-anchor-id="positional-embedding">Positional Embedding</h2>
<p>The character embeddings have no information of the relative positions of the tokens, so a positional embedding is used to inject this information. Because the maximum length of our training sequence is <code>block_size</code>, the parameter <code>num_embeddings</code> from the <code>nn.Embedding</code> would be the same as <code>block_size</code>. Also, because we want to sum these two embeddings and feed them to the network, the dimension of the positional embeddings is the same as the token embeddings.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BigramLanguageModel(nn.Module):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size):</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.token_embedding_table <span class="op">=</span> nn.Embedding(vocab_size, n_embed)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># position embedding table</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.position_embedding_table <span class="op">=</span> nn.Embedding(block_size, n_embed)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(n_embed, vocab_size)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, idx, targets<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>        token_embed <span class="op">=</span> <span class="va">self</span>.token_embedding_table(idx)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>        posit_embed <span class="op">=</span> <span class="va">self</span>.position_embedding_table(idx)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sum of token and positional embeddings </span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>        embeded <span class="op">=</span> token_embed <span class="op">+</span> posit_embed</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.linear(embedded)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># !!! the rest of the code is the same !!!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="attention" class="level2">
<h2 class="anchored" data-anchor-id="attention">Attention</h2>
<p>Before talking about attention mechanism, let’s talk about the dot product of two vectors.</p>
<section id="dot-product" class="level3">
<h3 class="anchored" data-anchor-id="dot-product">Dot Product</h3>
<p>The <a href="https://www.wikiwand.com/en/Dot_product">dot product</a> of two Euclidean vectors a and b is defined by</p>
<p><span class="math display">\[\vec{a} \cdot \vec{b} = \|a\| \cdot \|b\| cos(\theta)\]</span></p>
<p>What is <span class="math inline">\(\|a\|cos(\theta)\)</span>?</p>
<p><img src="320px-Dot_Product.png" class="img-fluid" alt="dot-product-projection"> <em>scalar projection <a href="https://www.wikiwand.com/en/Dot_product">source</a></em></p>
<p>It is the scalar projection of <span class="math inline">\(\vec{a}\)</span> on <span class="math inline">\(\vec{b}\)</span>. Because of this, the dot product is considered as the similarity between two vectors. The higher the product, the more similar two vectors. For example, let’s take the learned embedding from our last model and compute their dot products.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>char1 <span class="op">=</span> <span class="st">'a'</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>char2 <span class="op">=</span> <span class="st">'z'</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>char3 <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>char_embedding <span class="op">=</span> model.token_embedding_table.weight</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_dp(char1, char2):</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">sum</span>(char_embedding[stoi[char1]] <span class="op">*</span> char_embedding[stoi[char2]])</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dot product of </span><span class="sc">{</span>char1<span class="sc">}</span><span class="ss"> and </span><span class="sc">{</span>char1<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>calc_dp(char1, char1)<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dot product of </span><span class="sc">{</span>char1<span class="sc">}</span><span class="ss"> and </span><span class="sc">{</span>char2<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>calc_dp(char1, char2)<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dot product of </span><span class="sc">{</span>char1<span class="sc">}</span><span class="ss"> and </span><span class="sc">{</span>char3<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>calc_dp(char1, char3)<span class="sc">:.6f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dot product of a and a: 58.615814
Dot product of a and z: 9.842464
Dot product of a and e: 14.203679</code></pre>
</div>
</div>
<p>The dot product of the feature vectors of <code>a</code> and itself is way greater than it with <code>z</code>. <code>a</code> is more similar to <code>e</code> then <code>z</code>.</p>
</section>
<section id="attention-mechanism" class="level3">
<h3 class="anchored" data-anchor-id="attention-mechanism">Attention Mechanism</h3>
<p>What is attention?</p>
<blockquote class="blockquote">
<p>An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.</p>
</blockquote>
<p>Here is how we compute the attentaion score.</p>
<p><span class="math display">\[Attention(Q,K,V)=softmax\bigl( \frac{QK^T}{\sqrt{d_k}}\bigr) V\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="attention-multi-head.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">attention-multihead</figcaption><p></p>
</figure>
</div>
<p>Because <span class="math inline">\(Q\)</span>, <span class="math inline">\(V\)</span>, and <span class="math inline">\(T\)</span> are all from the same source in GPT, we call this operation as <strong>self-attention</strong>.</p>
<p><span class="math inline">\(X_{m\times n}\)</span>, as <span class="math inline">\(m\)</span> is the number of tokens, and <span class="math inline">\(n\)</span> is the token dimension. Each row is the token embedding for each token in the input.</p>
<p>Linear transformation:</p>
<ul>
<li><span class="math inline">\(X_{m\times n} \cdot W^Q_{n\times k} = Q_{m\times k}\)</span> to obtain the query space.</li>
<li><span class="math inline">\(X_{m\times n} \cdot W^K_{n\times k} = K_{m\times k}\)</span> to obtain the key space.</li>
<li><span class="math inline">\(X_{m\times n} \cdot W^V_{n\times k} = V_{m\times k}\)</span> to obtain the value space.</li>
</ul>
<p>Why? We want to impart meaning to these matrices. And this is one of those aspects of mathematics where a mathematician trying to create a formula will decide or impart intuitive representations or intuitive meanings behind matrices and then allow a training phase to learn the proper weight matrices, these Ws, WQ, WK, and WV. We want to learn the values in this matrix that impart the meaning as the architect intended. So the intended intuitive meaning of these matrices is:</p>
<ul>
<li>The query matrix is meant to represent a piece of information we are looking for in a query we have.</li>
<li>The key matrix is intuitively meant to represent the relevance of each word to our query. And the key matrix represents how important each word is to my overall query.</li>
<li>The value matrix intuitively represents the contextless meaning of our input tokens.</li>
</ul>
<p><span class="math inline">\(Q\cdot K^T\)</span> is attention score. The larger the value is, the closer the vectors are and the more attention the word has.</p>
<p>For example, in the sentence, <code>I like cats</code>, the attention score for <code>like</code> is <code>[.23, .87, .70]</code>. Divide the <span class="math inline">\(\sqrt {d_k}\)</span> and then apply softmax to it, resulting in <code>[.22, .42, .36]</code>. In other words, when focusing on the word “like,” I should pay about 22% attention to “I,” 35% to “cats,” and the rest 42% to “like.”</p>
<p>Finally, we multiply the attention probability with its contextual embedding of the word “like.”</p>
<p>So by taking the attention scores and multiplying them by our value matrix, we are explicitly taking those tokens, forcing them to look at each other. Then once they’ve looked at each other, they adjust the value matrix to represent all tokens in our sequence. And the dimension we have for each of those tokens is now no longer a semantic representation as <span class="math inline">\(V\)</span> was. It is now a relevance embedding dimension. Each token now has 300 dimensions of how it is relevant to the sequence and why we’re saying it in the first place.</p>
<p>How can we preserve the information from the previous tokens while not peeking the future tokens.</p>
<p><span class="math display">\[attention(q, k, v) = \sum_i similarity(q, k_i)\times v_i\]</span></p>
<div id="fig-heatap" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>word <span class="op">=</span> <span class="st">"together"</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(word)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>dp <span class="op">=</span> torch.zeros((n, n))</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>            dp[i, j] <span class="op">=</span> calc_dp(word[i], word[j])</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.array(dp), aspect<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(np.arange(n), labels<span class="op">=</span><span class="bu">list</span>(word))</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>ax.set_yticks(np.arange(n), labels<span class="op">=</span><span class="bu">list</span>(word))</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-heatap-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<pre><code>&lt;Figure size 768x768 with 0 Axes&gt;</code></pre>
<p></p><figcaption class="figure-caption">(a) A heatmap plot for “together”</figcaption><p></p>
</figure>
</div>
<div class="cell-output cell-output-display">
<div id="fig-heatap-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-heatap-output-2.png" data-ref-parent="fig-heatap" width="558" height="411" class="figure-img"></p>
<p></p><figcaption class="figure-caption">(b)</figcaption><p></p>
</figure>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: <strong>?(caption)</strong></figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Head(nn.Module):</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># input_dim: batch_size, block_size, n_embed</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># B: batch_size</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># T: block_size</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># C: n_embed</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, head_size):</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.query <span class="op">=</span> nn.Linear(n_embed, head_size, bias<span class="op">=</span><span class="va">False</span>) <span class="co"># C, head_size</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.key <span class="op">=</span> nn.Linear(n_embed, head_size, bias<span class="op">=</span><span class="va">False</span>)   <span class="co"># C, head_size</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.value <span class="op">=</span> nn.Linear(n_embed, head_size, bias<span class="op">=</span><span class="va">False</span>) <span class="co"># C, head_size</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># not a model parameter</span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'tril'</span>, torch.tril(torch.ones(block_size, block_size)))   <span class="co"># block_size, block_size</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>        B, T, C <span class="op">=</span> x.shape</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.query(x) <span class="co"># B, T, head_size</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> <span class="va">self</span>.key(x)   <span class="co"># B, T, head_size</span></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> torch.matmul(q, k.transpose(<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>)) <span class="op">/</span> math.sqrt(C)   <span class="co"># B, T, T</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> score.masked_fill(<span class="va">self</span>.tril[:T, :T] <span class="op">==</span> <span class="dv">0</span>, <span class="bu">float</span>(<span class="st">"-inf"</span>))    <span class="co"># B, T, T</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> F.softmax(score, dim<span class="op">=-</span><span class="dv">1</span>) <span class="co"># B, T, T</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> <span class="va">self</span>.value(x)   <span class="co"># B, T, d_k</span></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> score <span class="op">@</span> v     <span class="co"># (B, T, T)@(B, T, d_k) = (B, T, d_k)</span></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BigramLanguageModel(nn.Module):</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size):</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.token_embedding_table <span class="op">=</span> nn.Embedding(vocab_size, n_embed)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># position embedding table</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.position_embedding_table <span class="op">=</span> nn.Embedding(block_size, n_embed)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># self attention</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.self_attn <span class="op">=</span> Head(n_embed)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(n_embed, vocab_size)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, idx, targets<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>        B, T <span class="op">=</span> idx.shape</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>        token_embed <span class="op">=</span> <span class="va">self</span>.token_embedding_table(idx)  <span class="co"># B, T, C</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># changed</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>        posit_embed <span class="op">=</span> <span class="va">self</span>.position_embedding_table(torch.arange(T, device<span class="op">=</span>device)) <span class="co"># T, C</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sum of token and positional embeddings </span></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> token_embed <span class="op">+</span> posit_embed  <span class="co"># B, T, C</span></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># apply self attention</span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.self_attn(x)  <span class="co"># B, T, C</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.linear(x) <span class="co"># B, T, vocab_size</span></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> targets <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="va">None</span></span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a>            B, T, C <span class="op">=</span> logits.shape</span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> logits.view(B<span class="op">*</span>T, C)</span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> targets.view(B<span class="op">*</span>T)</span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> F.cross_entropy(logits, targets)</span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits, loss</span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate(<span class="va">self</span>, idx, max_length):</span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(max_length):</span>
<span id="cb41-36"><a href="#cb41-36" aria-hidden="true" tabindex="-1"></a>            logits, loss <span class="op">=</span> <span class="va">self</span>(idx[:, <span class="op">-</span>block_size:])</span>
<span id="cb41-37"><a href="#cb41-37" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> logits[:, <span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb41-38"><a href="#cb41-38" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb41-39"><a href="#cb41-39" aria-hidden="true" tabindex="-1"></a>            idx_next <span class="op">=</span> torch.multinomial(probs, num_samples<span class="op">=</span><span class="dv">1</span>) <span class="co"># (B, 1)</span></span>
<span id="cb41-40"><a href="#cb41-40" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> torch.cat((idx, idx_next), dim<span class="op">=</span><span class="dv">1</span>) <span class="co"># (B, T+1)</span></span>
<span id="cb41-41"><a href="#cb41-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> idx</span>
<span id="cb41-42"><a href="#cb41-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-43"><a href="#cb41-43" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BigramLanguageModel(vocab_size).to(device)</span>
<span id="cb41-44"><a href="#cb41-44" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> torch.zeros((<span class="dv">1</span>, <span class="dv">1</span>), dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>device)</span>
<span id="cb41-45"><a href="#cb41-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(decode(model.generate(idx, max_length<span class="op">=</span><span class="dv">10</span>).squeeze().tolist()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
JvJRd$PlIV</code></pre>
</div>
</div>
</section>
<section id="demystifying-qkv" class="level3">
<h3 class="anchored" data-anchor-id="demystifying-qkv">Demystifying QKV</h3>
<p>How do we understand attention from intuition? Here is a great answer from <a href="https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms">Cross Validated</a>.</p>
<blockquote class="blockquote">
<p>The key/value/query concept is analogous to retrieval systems. For example, when you search for videos on Youtube, the search engine will map your <strong>query</strong> (text in the search bar) against a set of <strong>keys</strong> (video title, description, etc.) associated with candidate videos in their database, then present you the best matched videos (<strong>values</strong>).</p>
</blockquote>
<p>In other words, the query is what we are looking for in the sequence, while the key is what we have in the sequence. The dot product of the query and the key is to measure how close what we are looking for v.s what we have. It determines how much “attention” each word should pay to the other words. <span class="math inline">\(Q\times K^T\)</span> is the attention score. The higher the value is, the closer the vectors are and the more attention the word has.</p>
<p>Imagine that you’re at the supermarket buying all the ingredients you need for your dinner. You have the dish’s recipe, and each of the required ingredients can be thought of as a query. As you scan the shelves, you look at the labels (keys) and check whether they match an ingredient on your list (similarity function). If you have a match, then you take the item (value) from the shelf.</p>
</section>
<section id="multi-head-attention" class="level3">
<h3 class="anchored" data-anchor-id="multi-head-attention">Multi-head Attention</h3>
<p>Two heads are better than one. It’s even better if we have three. :P</p>
<p>In practice, the self-attention layer applies 3 independent linear transformations to each embedding to generate the query, key, and value vectors. These transformations project the embeddings and each projection carries its own set of learnable parameters, which allows the self-attention layer to focus on different semantic aspects of the sequence.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiHeadAttention(nn.Module):</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_head, head_size):</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>.<span class="fu">__init__</span>()</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.heads <span class="op">=</span> nn.ModuleList([Head(head_size) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_head)]) <span class="co"># shape?</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([h(x) <span class="cf">for</span> h <span class="kw">in</span> <span class="va">self</span>.heads], dim<span class="op">=-</span><span class="dv">1</span>) <span class="co"># shape?</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="feed-forward" class="level3">
<h3 class="anchored" data-anchor-id="feed-forward">Feed-Forward</h3>
<p>Instead of processing the whole sequence of embeddings as a single vector, it processes each embedding independently.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FeedForward(nn.Module):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_embed):</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(n_embed, n_embed),</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="residual-connection" class="level3">
<h3 class="anchored" data-anchor-id="residual-connection">Residual Connection</h3>
<p>Skip connections pass a tensor to the next layer of the model without processing and add it to the procesed tensor. Residual connection.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiHeadAttention(nn.Module):</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_head, head_size):</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>.<span class="fu">__init__</span>()</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.heads <span class="op">=</span> nn.ModuleList([Head(head_size) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_head)])</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.proj <span class="op">=</span> nn.Linear(n_embed, n_embed)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.cat([h(x) <span class="cf">for</span> h <span class="kw">in</span> <span class="va">self</span>.heads], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.proj(x)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="layer-normalization" class="level3">
<h3 class="anchored" data-anchor-id="layer-normalization">Layer Normalization</h3>
<p>Normalize each input in the batch to have zero mean and unity variance.</p>
</section>
<section id="refactor" class="level3">
<h3 class="anchored" data-anchor-id="refactor">Refactor</h3>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Block(nn.Module):</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_embed, n_head):</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>.<span class="fu">__init__</span>()</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn <span class="op">=</span> MultiHeadAttention(n_head, head_size)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ff <span class="op">=</span> FeedForward(n_embed)</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.attn(x)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.ff(x)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="standardization" class="level3">
<h3 class="anchored" data-anchor-id="standardization">Standardization</h3>
<p>The softmax function is used to standardize the dot products. The values represent how much attention should we pay to the word respectively.</p>
</section>
<section id="weighted-sum" class="level3">
<h3 class="anchored" data-anchor-id="weighted-sum">Weighted Sum</h3>
<p>New embeddings after paying attention. Here is another way to understand the weighted sum after paying attention. When you see the word “flies” in a book, you might think that’s an annoying insect. However, if you pay attention to the context, “a airplane flies high in the sky,” you realize that “flies” is a verb instead. The embeddings generated in this way are called <em>contextualized embeddings</em>.</p>
</section>
<section id="scaled-dot-product-attention" class="level3">
<h3 class="anchored" data-anchor-id="scaled-dot-product-attention">Scaled dot-product attention</h3>
<ol type="1">
<li>Project each token embedding into three vectors called <em>query</em>, <em>key</em>, and <em>value</em>.</li>
<li>Compute attention score.</li>
<li>Compute attention weights.</li>
<li>Update token embeddings.</li>
</ol>
<p>QK -&gt; Martix Multiplication -&gt; Scale -&gt; Mask(Optinal) -&gt; Softmax -&gt; Multiplied by V</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>model_ckpt <span class="op">=</span> <span class="st">"bert-base-uncased"</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_ckpt)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BertModel.from_pretrained(model_ckpt)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"time flies like an arrow"</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>show(model, <span class="st">"bert"</span>, tokenizer, text, display_mode<span class="op">=</span><span class="st">"light"</span>, layer<span class="op">=</span><span class="dv">0</span>, head<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="co"># tokenization</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tokenizer(text, return_tensors<span class="op">=</span><span class="st">"pt"</span>, add_special_tokens<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> AutoConfig.from_pretrained(model_ckpt)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>token_emb <span class="op">=</span> nn.Embedding(config.vocab_size, config.hidden_size)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>inputs_embeds <span class="op">=</span> token_emb(inputs.input_ids)</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a><span class="co"># scaled dot product</span></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> key <span class="op">=</span> value <span class="op">=</span> inputs_embeds  <span class="co"># as it is</span></span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>dim_k <span class="op">=</span> key.size(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> torch.bmm(query, key.transpose(<span class="dv">1</span>, <span class="dv">2</span>)) <span class="op">/</span> sqrt(dim_k)</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>scores.size()</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> F.softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a>weights.<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a>attn_outputs <span class="op">=</span> torch.bmm(weights, value)</span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a><span class="co"># scaled dot product function</span></span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scaled_dot_product_attention(query, key, value):</span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a>    dim_k <span class="op">=</span> query.size(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> torch.bmm(query, key.transpose(<span class="dv">1</span>, <span class="dv">2</span>)) <span class="op">/</span> sqrt(dim_k)</span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> F.softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.bmm(weights, value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>More general definition of attention: Given a set of vector <em>values</em>, and a vector <em>query</em>, attention is a technique to compute a weighted sum of the values, dependent on the query. - The weighted sum is a selective summary of the information contained in the values, where the query determines which values to focus on. - Attention is a way to obtain a <em>fixed-size representation of an arbitrary set of representations</em> (the values), dependent on some other representation (the query).</p>
<p>Self attention doesn’t consider the position of each word. If we change the order our input sequence, we will still get the same values for each word.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Self_Attention(nn.Module):</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, dim_k, dim_v):</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Self_Attention, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.q <span class="op">=</span> nn.Linear(input_dim, dim_k)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.k <span class="op">=</span> nn.Linear(input_dim, dim_k)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.v <span class="op">=</span> nn.Linear(input_dim, dim_v)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm_fact <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> math.sqrt(dim_k)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>        Q <span class="op">=</span> <span class="va">self</span>.q(x)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>        K <span class="op">=</span> <span class="va">self</span>.k(x)</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>        V <span class="op">=</span> <span class="va">self</span>.v(x)</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>        attention <span class="op">=</span> nn.Softmax(</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=-</span><span class="dv">1</span>)(torch.bmm(Q, K.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>))) <span class="op">*</span> <span class="va">self</span>.norm_fact</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> torch.bmm(attention, V)</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The main idea behind attention is that instead of producing a single hidden state for the input sequence, the encoder outputs a hidden state at each step that the decoder can access. However, using all the states at the same time would create a huge input for the decoder, so some mechanism is needed to prioritize which states to use. This is where attention comes in: it lets the decoder assign a different amount of weight, or “attention,” to each of the encoder states at every decoding timestep. By focusing on which input tokens are most relevant at each timestep, these attention-based models are able to learn nontrivial alignments between the words in a generated translation and those in a source sentence.</p>
<p>The basic idea of self-attention is to allow attention to operate on all the states in the same layer of the neural network.</p>
</section>
</section>
<section id="multi-head-attention-layer" class="level2">
<h2 class="anchored" data-anchor-id="multi-head-attention-layer">Multi-head Attention Layer</h2>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionHead(nn.Module):</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, embed_dim, head_dim):</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(AttentionHead, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.q <span class="op">=</span> nn.Linear(embed_dim, head_dim)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.k <span class="op">=</span> nn.Linear(embed_dim, head_dim)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.v <span class="op">=</span> nn.Linear(embed_dim, head_dim)</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>        attn_outputs <span class="op">=</span> scaled_dot_product_attention(</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.q(x), <span class="va">self</span>.k(x), <span class="va">self</span>.v(x)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> attn_outputs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiHeadAttention(nn.Module):</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, hidden_size, num_attention_heads):</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MultiHeadAttention, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>        embed_dim <span class="op">=</span> hidden_size</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>        num_heads <span class="op">=</span> num_attention_heads</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>        head_dim <span class="op">=</span> embed_dim <span class="op">//</span> num_heads</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.heads <span class="op">=</span> nn.ModuleList(</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>            [AttentionHead(embed_dim, head_dim) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_heads)]</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_linear <span class="op">=</span> nn.Linear(embed_dim, embed_dim)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, hidden_state):</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.cat([h(hidden_state) <span class="cf">for</span> h <span class="kw">in</span> <span class="va">self</span>.heads], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.output_linear(x)</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Embeddings(nn.Module):</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config):</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.token_embeddings <span class="op">=</span> nn.Embedding(config.vocab_size,</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>                                             config.hidden_size)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.position_embeddings <span class="op">=</span> nn.Embedding(config.max_position_embeddings,</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>                                                config.hidden_size)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer_norm <span class="op">=</span> nn.LayerNorm(config.hidden_size, eps<span class="op">=</span><span class="fl">1e-12</span>)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout()</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_ids):</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create position IDs for input sequence</span></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>        seq_length <span class="op">=</span> input_ids.size(<span class="dv">1</span>)</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>        position_ids <span class="op">=</span> torch.arange(seq_length, dtype<span class="op">=</span>torch.<span class="bu">long</span>).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create token and position embeddings</span></span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>        token_embeddings <span class="op">=</span> <span class="va">self</span>.token_embeddings(input_ids)</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>        position_embeddings <span class="op">=</span> <span class="va">self</span>.position_embeddings(position_ids)</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine token and position embeddings</span></span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> token_embeddings <span class="op">+</span> position_embeddings</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> <span class="va">self</span>.layer_norm(embeddings)</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> <span class="va">self</span>.dropout(embeddings)</span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> embeddings</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul class="task-list">
<li><input type="checkbox" checked="">What is auto-regressive?</li>
<li><input type="checkbox" checked="">Multi-head self-attention</li>
<li><input type="checkbox" checked="">position-wise fully connected feed-forward network</li>
<li><input type="checkbox" checked="">residual connection</li>
<li><input type="checkbox" checked="">Layer normalization, <span class="math inline">\(LayerNorm(x+Sublayer(x))\)</span></li>
<li><input type="checkbox">Masking for Decoder</li>
<li><input type="checkbox">What does <span class="math inline">\(QK^T\)</span> mean? Correlation between two words. (see below)</li>
<li><input type="checkbox">What exactly are <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(V\)</span>? https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms</li>
<li><input type="checkbox">What do the dimensions look like?</li>
<li><input type="checkbox">Pre and post layer normalization from the book.</li>
</ul>
</section>
<section id="docoder" class="level2">
<h2 class="anchored" data-anchor-id="docoder">Docoder</h2>
<p>The decoder has two attention sublayers: masked multi-head self-attention layer and encoder-decoder attention layer. The masked layer ensures that the model doesn’t cheat by looking forward when generating new tokens. The other attention layer performs attention over the output key and value vectors of the encoder stack, with the itermediate representations of the decoder acting as the queries. This way, the later layer learns how to relate tokens from two different sequences.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># updated scaled dot product</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scaled_dot_product_attention(query, key, value, mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    dim_k <span class="op">=</span> query.size(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> torch.bmm(query, key.transpose(<span class="dv">1</span>, <span class="dv">2</span>)) <span class="op">/</span> sqrt(dim_k)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mask <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> scores.masked_fill(mask <span class="op">==</span> <span class="dv">0</span>, <span class="bu">float</span>(<span class="st">"-inf"</span>))</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> F.softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> weights.bmm(value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="demystifying-encoder-decoder-attention" class="level2">
<h2 class="anchored" data-anchor-id="demystifying-encoder-decoder-attention">Demystifying Encoder-Decoder Attention</h2>
<blockquote class="blockquote">
<p>Let’s see if we can shed some light on the mysteries of encoder-decoder attention. Imagine you (the decoder) are in class taking an exam. Your task is to predict the next word based on the previous words (decoder inputs), which sounds simple but is incredibly hard (try it yourself and predict the next words in a passage of this book). Fortunately, your neighbor (the encoder) has the full text. Unfortunately, they’re a foreign exchange student and the text is in their mother tongue. Cunning students that you are, you figure out a way to cheat anyway. You draw a little cartoon illustrating the text you already have (the query) and give it to your neighbor. They try to figure out which passage matches that description (the key), draw a cartoon describing the word following that passage (the value), and pass that back to you. With this system in place, you ace the exam.</p>
</blockquote>
<section id="unknown" class="level3">
<h3 class="anchored" data-anchor-id="unknown">Unknown</h3>
<p>“Fine, Sheldon. You have my undivided attention.”</p>
<p>“xxx xxx flies xxx xxx xxx”</p>
<p>Encoder:“Decoder, I want you to pay [percent] attention to [word] when you generate the next word.” “Here is how much attention you need to pay for each token when generating the next token.” Decoder:“OK. [generating new word]…Hey, look, this is what I generated. Am I done? What should I generate next?”</p>
</section>
</section>
<section id="reference" class="level2">
<h2 class="anchored" data-anchor-id="reference">Reference</h2>
<p>[1] https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html [2] https://jalammar.github.io/illustrated-transformer/ [3] https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html [4] https://www.youtube.com/watch?v=ptuGllU5SQQ&amp;list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ&amp;index=9 [5] https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms [6] https://web.stanford.edu/class/cs224n/readings/cs224n-self-attention-transformers-2023_draft.pdf [7] https://learning.oreilly.com/library/view/natural-language-processing/9781098136789/ [8] https://github.com/jessevig/bertviz</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>