{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "from collections import Counter\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "\n",
    "counter = Counter()\n",
    "for word in words:\n",
    "  chs = \".\" + word + \".\"\n",
    "  for c1, c2, c3 in zip(chs, chs[1:], chs[2:]):\n",
    "    trigram = (c1, c2, c3)\n",
    "    counter[trigram] += 1\n",
    "print(counter.most_common(5))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(('a', 'h', '.'), 1714), (('n', 'a', '.'), 1673), (('a', 'n', '.'), 1509), (('o', 'n', '.'), 1503), (('.', 'm', 'a'), 1453)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "import torch.nn.functional as F\n",
    "xs, ys = [], []\n",
    "\n",
    "for word in words:\n",
    "  chs = list(\".\" + word + \".\")\n",
    "  for c1, c2, c3 in zip(chs, chs[1:], chs[2:]):\n",
    "    idx1 = stoi[c1]\n",
    "    idx2 = stoi[c2]\n",
    "    idx3 = stoi[c3]\n",
    "    xs.append((idx1, idx2))\n",
    "    ys.append(idx3)\n",
    "\n",
    "# tensor function returns the same type as its original\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "xs.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([196113, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "ys.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([196113])"
      ]
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "xenc.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([196113, 2, 27])"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "W.shape\n",
    ""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "g = torch.Generator().manual_seed(420)\n",
    "W = torch.randn((27, 27, 27), generator=g, requires_grad=True)\n",
    "# log-counts\n",
    "logits = W[xs[:, 0], xs[:, 1], ...]\n",
    "# counts\n",
    "counts = logits.exp()\n",
    "# probability\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "probs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.1219, 0.0087, 0.0157,  ..., 0.0374, 0.1633, 0.0162],\n",
       "        [0.0143, 0.0108, 0.0063,  ..., 0.0264, 0.0188, 0.0181],\n",
       "        [0.0192, 0.0517, 0.0178,  ..., 0.0071, 0.0315, 0.0358],\n",
       "        ...,\n",
       "        [0.0030, 0.0031, 0.0078,  ..., 0.0260, 0.0391, 0.0318],\n",
       "        [0.0515, 0.0135, 0.0502,  ..., 0.0560, 0.0064, 0.0056],\n",
       "        [0.0192, 0.0194, 0.0069,  ..., 0.0718, 0.0414, 0.0128]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "lr = 10\n",
    "steps = 200\n",
    "\n",
    "for i in range(steps):\n",
    "    # forward pass\n",
    "    logits = W[xs[:, 0], xs[:, 1], ...]\n",
    "    counts = logits.exp()\n",
    "    probs = (counts / counts.sum(1, keepdim=True))\n",
    "    probs = probs[torch.arange(len(ys)), ys]\n",
    "    loss = -probs.log().mean() + 0.01 * (W**2).mean()\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -lr * W.grad\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'{i} loss={loss.item():.4f}')\n",
    "print(f'{i} loss={loss.item():.4f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 loss=2.6713\n",
      "10 loss=2.6553\n",
      "20 loss=2.6403\n",
      "30 loss=2.6261\n",
      "40 loss=2.6128\n",
      "50 loss=2.6001\n",
      "60 loss=2.5881\n",
      "70 loss=2.5766\n",
      "80 loss=2.5657\n",
      "90 loss=2.5554\n",
      "100 loss=2.5454\n",
      "110 loss=2.5360\n",
      "120 loss=2.5269\n",
      "130 loss=2.5182\n",
      "140 loss=2.5099\n",
      "150 loss=2.5019\n",
      "160 loss=2.4942\n",
      "170 loss=2.4868\n",
      "180 loss=2.4797\n",
      "190 loss=2.4728\n",
      "199 loss=2.4669\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.', *list(w), '.']\n",
    "    for c1, c2, c3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[c1]\n",
    "        ix2 = stoi[c2]\n",
    "        ix3 = stoi[c3]\n",
    "        xs.append((ix1, ix2))\n",
    "        ys.append(ix3)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "n = len(ys)\n",
    "xs.shape, ys.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([196113, 2]), torch.Size([196113]))"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "idxs = torch.randperm(n)\n",
    "idxs_tra = idxs[:int(n*0.8)]\n",
    "idxs_val = idxs[int(n*0.8):int(n*0.9)]\n",
    "idxs_tst = idxs[int(n*0.9):]\n",
    "idxs_tra.shape, idxs_val.shape, idxs_tst"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([156890]),\n",
       " torch.Size([19611]),\n",
       " tensor([190443,  65949,  15673,  ..., 101980,   9866,  74836]))"
      ]
     },
     "metadata": {},
     "execution_count": 172
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "W = torch.randn((27 * 2, 27), requires_grad=True)\n",
    "xenc_train = F.one_hot(xs[idxs_tra, :], num_classes=27).float().view(-1, 27*2)\n",
    "xenc_val = F.one_hot(xs[idxs_val, :], num_classes=27).float().view(-1, 27*2)\n",
    "xenc_test = F.one_hot(xs[idxs_tst, :], num_classes=27).float().view(-1, 27*2)\n",
    "y_train = ys[idxs_tra]\n",
    "y_val = ys[idxs_val]\n",
    "y_test = ys[idxs_tst]\n",
    "W.shape, xenc_train.shape, xenc_val.shape, xenc_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([54, 27]),\n",
       " torch.Size([156890, 54]),\n",
       " torch.Size([19611, 54]),\n",
       " torch.Size([19612, 54]))"
      ]
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "lr = 10\n",
    "steps = 200\n",
    "\n",
    "for i in range(steps):\n",
    "    # forward pass\n",
    "    logits = xenc_train @ W\n",
    "    counts = logits.exp()\n",
    "    prob = (counts / counts.sum(1, keepdim=True))\n",
    "    prob = prob[torch.arange(len(y_train)), y_train]\n",
    "    loss = -prob.log().mean() + 0.01 * (W**2).mean()\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        vlogits = xenc_val @ W\n",
    "        vcounts = vlogits.exp()\n",
    "        vprob = (vcounts / vcounts.sum(1, keepdim=True))\n",
    "        vprob = vprob[torch.arange(len(y_val)), y_val]\n",
    "        val_loss = -vprob.log().mean()\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -lr * W.grad\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'{i} train_loss={loss.item():.4f} | val_loss={val_loss.item():.4f}')\n",
    "print(f'{i} train_loss={loss.item():.4f} | val_loss={val_loss.item():.4f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 train_loss=4.2478 | val_loss=4.2451\n",
      "10 train_loss=3.0335 | val_loss=3.0364\n",
      "20 train_loss=2.7437 | val_loss=2.7439\n",
      "30 train_loss=2.6129 | val_loss=2.6109\n",
      "40 train_loss=2.5374 | val_loss=2.5338\n",
      "50 train_loss=2.4878 | val_loss=2.4830\n",
      "60 train_loss=2.4526 | val_loss=2.4470\n",
      "70 train_loss=2.4262 | val_loss=2.4200\n",
      "80 train_loss=2.4057 | val_loss=2.3990\n",
      "90 train_loss=2.3894 | val_loss=2.3823\n",
      "100 train_loss=2.3760 | val_loss=2.3686\n",
      "110 train_loss=2.3649 | val_loss=2.3572\n",
      "120 train_loss=2.3555 | val_loss=2.3476\n",
      "130 train_loss=2.3474 | val_loss=2.3394\n",
      "140 train_loss=2.3405 | val_loss=2.3322\n",
      "150 train_loss=2.3344 | val_loss=2.3260\n",
      "160 train_loss=2.3290 | val_loss=2.3205\n",
      "170 train_loss=2.3242 | val_loss=2.3156\n",
      "180 train_loss=2.3199 | val_loss=2.3113\n",
      "190 train_loss=2.3161 | val_loss=2.3073\n",
      "199 train_loss=2.3130 | val_loss=2.3041\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "g = torch.Generator().manual_seed(420)\n",
    "for _ in range(5):\n",
    "    name = ''\n",
    "    ix1 = stoi['.']\n",
    "    ix2 = stoi['.']\n",
    "    while True:\n",
    "        \n",
    "        xen = F.one_hot(torch.tensor((ix1, ix2)), 27).float().view(-1, 27*2)\n",
    "        logits = xen @ W\n",
    "        counts = logits.exp()\n",
    "        prob = (counts / counts.sum(1, keepdims=True))\n",
    "        ix3 = torch.multinomial(prob, num_samples=1, generator=g).item()\n",
    "        if ix3 == stoi['.']:\n",
    "            break\n",
    "        name += itos[ix3]\n",
    "        ix1 = ix2\n",
    "        ix2 = ix3\n",
    "    print(name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "raiusal\n",
      "leerstari\n",
      "iuamad\n",
      "ya\n",
      "amonzatlixann\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}